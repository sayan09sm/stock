{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = load_model('sayan_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 50, 256)           268288    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 793,857\n",
      "Trainable params: 793,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "   \n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# Amazon stock market\n",
    "ticker = \"AMZN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lp/6r1tkyt538x8924j8j7vqgs40000gn/T/ipykernel_81539/2995133739.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfuture_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True, test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low'])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df':                    open         high          low        close     adjclose  \\\n",
       " 1997-05-15     2.437500     2.500000     1.927083     1.958333     1.958333   \n",
       " 1997-05-16     1.968750     1.979167     1.708333     1.729167     1.729167   \n",
       " 1997-05-19     1.760417     1.770833     1.625000     1.708333     1.708333   \n",
       " 1997-05-20     1.729167     1.750000     1.635417     1.635417     1.635417   \n",
       " 1997-05-21     1.635417     1.645833     1.375000     1.427083     1.427083   \n",
       " ...                 ...          ...          ...          ...          ...   \n",
       " 2022-03-15  2857.000000  2959.699951  2840.000000  2947.330078  2947.330078   \n",
       " 2022-03-16  2970.000000  3063.000000  2947.070068  3062.080078  3062.080078   \n",
       " 2022-03-17  3052.810059  3149.969971  3042.800049  3144.780029  3144.780029   \n",
       " 2022-03-18  3136.260010  3231.879883  3120.219971  3225.010010  3225.010010   \n",
       " 2022-03-18  3136.260010  3231.879883  3120.219971  3225.010010  3225.010010   \n",
       " \n",
       "               volume ticker  \n",
       " 1997-05-15  72156000   AMZN  \n",
       " 1997-05-16  14700000   AMZN  \n",
       " 1997-05-19   6106800   AMZN  \n",
       " 1997-05-20   5467200   AMZN  \n",
       " 1997-05-21  18853200   AMZN  \n",
       " ...              ...    ...  \n",
       " 2022-03-15   3779200   AMZN  \n",
       " 2022-03-16   4247900   AMZN  \n",
       " 2022-03-17   3646700   AMZN  \n",
       " 2022-03-18   5141300   AMZN  \n",
       " 2022-03-18   5148138   AMZN  \n",
       " \n",
       " [6254 rows x 7 columns],\n",
       " 'column_scaler': {'adjclose': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       "  'volume': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       "  'open': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       "  'high': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       "  'low': MinMaxScaler(copy=True, feature_range=(0, 1))},\n",
       " 'last_sequence': array([[0.9050969 , 0.0246201 , 0.92608607, 0.92317384, 0.9097329 ],\n",
       "        [0.91124433, 0.03649679, 0.8958503 , 0.9058471 , 0.89594847],\n",
       "        [0.8954884 , 0.02293292, 0.89125186, 0.88981164, 0.8958754 ],\n",
       "        [0.9133864 , 0.02225111, 0.89659846, 0.904882  , 0.89613247],\n",
       "        [0.9167108 , 0.02180813, 0.90418404, 0.9119532 , 0.911573  ],\n",
       "        [0.9168797 , 0.01302171, 0.9103723 , 0.9115555 , 0.9205001 ],\n",
       "        [0.90937835, 0.02356657, 0.91362673, 0.9166886 , 0.9154426 ],\n",
       "        [0.9146947 , 0.02161649, 0.90906036, 0.9126214 , 0.9150096 ],\n",
       "        [0.9068663 , 0.01252383, 0.912574  , 0.9075095 , 0.9121142 ],\n",
       "        [0.9038824 , 0.01340498, 0.906482  , 0.9057914 , 0.9117002 ],\n",
       "        [0.89354736, 0.01833844, 0.9025062 , 0.8976358 , 0.90106285],\n",
       "        [0.9133194 , 0.02589318, 0.8949926 , 0.9048131 , 0.89890885],\n",
       "        [0.8978637 , 0.02936288, 0.9104258 , 0.90850645, 0.8999317 ],\n",
       "        [0.88089323, 0.02626972, 0.89142823, 0.8858452 , 0.88914824],\n",
       "        [0.8749791 , 0.02032607, 0.8730853 , 0.87350833, 0.8760512 ],\n",
       "        [0.8712257 , 0.01774908, 0.87516147, 0.8758601 , 0.87656   ],\n",
       "        [0.8654992 , 0.03758306, 0.8577751 , 0.85686564, 0.845568  ],\n",
       "        [0.88628197, 0.02554939, 0.8626621 , 0.8817276 , 0.8693646 ],\n",
       "        [0.88545084, 0.01939774, 0.8897823 , 0.88452744, 0.889473  ],\n",
       "        [0.86404073, 0.02043682, 0.8827043 , 0.8810462 , 0.87147266],\n",
       "        [0.86899513, 0.01744477, 0.8554478 , 0.8599863 , 0.8644884 ],\n",
       "        [0.8517271 , 0.0277094 , 0.8498635 , 0.84664726, 0.85292834],\n",
       "        [0.83768696, 0.02094432, 0.8480305 , 0.84407806, 0.845273  ],\n",
       "        [0.8128533 , 0.02996379, 0.83736414, 0.83744967, 0.81875956],\n",
       "        [0.76446474, 0.0742609 , 0.8009402 , 0.79980016, 0.7685333 ],\n",
       "        [0.77465767, 0.07024132, 0.7424246 , 0.76822233, 0.7321726 ],\n",
       "        [0.7502181 , 0.03904008, 0.7597522 , 0.76109016, 0.74728835],\n",
       "        [0.7442476 , 0.04134069, 0.773152  , 0.769495  , 0.7428154 ],\n",
       "        [0.7483495 , 0.03263227, 0.7520436 , 0.7645025 , 0.75380987],\n",
       "        [0.7716229 , 0.03112806, 0.7523669 , 0.76320064, 0.7461221 ],\n",
       "        [0.80162543, 0.03301362, 0.773152  , 0.7969393 , 0.7806021 ],\n",
       "        [0.81031173, 0.02382273, 0.80120736, 0.8040848 , 0.7986079 ],\n",
       "        [0.80719644, 0.03735772, 0.8281967 , 0.8219391 , 0.80529714],\n",
       "        [0.74410284, 0.10390208, 0.7570535 , 0.7645237 , 0.74830586],\n",
       "        [0.8448746 , 0.11734751, 0.8311679 , 0.85441846, 0.8147384 ],\n",
       "        [0.8464617 , 0.04472179, 0.84673727, 0.86232483, 0.85068506],\n",
       "        [0.86511046, 0.03192157, 0.8372813 , 0.85756034, 0.84148735],\n",
       "        [0.8639094 , 0.02842877, 0.8700019 , 0.86838853, 0.8669211 ],\n",
       "        [0.8521883 , 0.02817935, 0.84582883, 0.85185456, 0.85339105],\n",
       "        [0.82157177, 0.03243196, 0.8446772 , 0.8427524 , 0.82624435],\n",
       "        [0.8316173 , 0.03538356, 0.8105645 , 0.83982795, 0.8203777 ],\n",
       "        [0.838821  , 0.02248416, 0.84185034, 0.83748674, 0.8365461 ],\n",
       "        [0.8473464 , 0.02068527, 0.8321512 , 0.84187216, 0.8370711 ],\n",
       "        [0.8288586 , 0.02613971, 0.84473866, 0.8499058 , 0.835802  ],\n",
       "        [0.8178613 , 0.02593363, 0.8305961 , 0.82419014, 0.81628084],\n",
       "        [0.8049713 , 0.02714894, 0.80376446, 0.8108431 , 0.8032514 ],\n",
       "        [0.77617514, 0.02624179, 0.8100275 , 0.8043764 , 0.782499  ],\n",
       "        [0.81119376, 0.04383679, 0.74690014, 0.8043022 , 0.7546217 ],\n",
       "        [0.8242259 , 0.02535198, 0.8041465 , 0.81618565, 0.8071914 ],\n",
       "        [0.82301676, 0.02302825, 0.8141663 , 0.8186249 , 0.81604815],\n",
       "        [0.81003565, 0.01691512, 0.81580955, 0.81676364, 0.81132346],\n",
       "        [0.8149176 , 0.01809961, 0.80574435, 0.8109333 , 0.80468285],\n",
       "        [0.7926442 , 0.02670114, 0.82007927, 0.81586224, 0.7944325 ],\n",
       "        [0.78053975, 0.02464802, 0.7860254 , 0.7836268 , 0.7779312 ],\n",
       "        [0.7366364 , 0.03716704, 0.776858  , 0.7743178 , 0.74334574],\n",
       "        [0.7289233 , 0.03944358, 0.7300455 , 0.74570954, 0.7225419 ],\n",
       "        [0.7464273 , 0.03510718, 0.74509656, 0.74332595, 0.74016076],\n",
       "        [0.78684807, 0.06034071, 0.7781485 , 0.7879989 , 0.77885675],\n",
       "        [0.77991503, 0.02844032, 0.79893357, 0.7933043 , 0.7863848 ],\n",
       "        [0.7602288 , 0.03098072, 0.7797303 , 0.7815057 , 0.7621119 ],\n",
       "        [0.7897917 , 0.03170201, 0.7629986 , 0.78434265, 0.76815176],\n",
       "        [0.8205557 , 0.0362156 , 0.79319155, 0.81173134, 0.797125  ],\n",
       "        [0.8427272 , 0.03042603, 0.8153179 , 0.83479035, 0.82302964],\n",
       "        [0.8642365 , 0.04481905, 0.8376153 , 0.8565077 , 0.84397954],\n",
       "        [0.8642365 , 0.0448849 , 0.8376153 , 0.8565077 , 0.84397954]],\n",
       "       dtype=float32),\n",
       " 'X_train': array([[[0.00460968, 0.08005046, 0.00477577, 0.00484726, 0.0046239 ],\n",
       "         [0.00460432, 0.06504882, 0.00457003, 0.0046325 , 0.0045346 ],\n",
       "         [0.00474105, 0.0616475 , 0.00466087, 0.00471204, 0.00464284],\n",
       "         ...,\n",
       "         [0.00517536, 0.06944107, 0.00507502, 0.00522906, 0.00513804],\n",
       "         [0.00540324, 0.08745016, 0.00518992, 0.00538284, 0.00521922],\n",
       "         [0.00526115, 0.0625402 , 0.00535291, 0.00534307, 0.00527875]],\n",
       " \n",
       "        [[0.008985  , 0.05185859, 0.00905889, 0.00908415, 0.00899951],\n",
       "         [0.0089421 , 0.07244757, 0.00892529, 0.00886144, 0.0088588 ],\n",
       "         [0.00890189, 0.04763294, 0.00888789, 0.00882962, 0.00884527],\n",
       "         ...,\n",
       "         [0.00893674, 0.0272385 , 0.0088291 , 0.00884818, 0.00886962],\n",
       "         [0.0090976 , 0.08734712, 0.00892529, 0.00915309, 0.00904281],\n",
       "         [0.0091673 , 0.04676624, 0.00907492, 0.00913718, 0.00920517]],\n",
       " \n",
       "        [[0.04822077, 0.05948364, 0.04836585, 0.04851006, 0.04843691],\n",
       "         [0.04770335, 0.03896689, 0.04825363, 0.04818128, 0.04808242],\n",
       "         [0.04855857, 0.03960729, 0.048438  , 0.04818128, 0.04849914],\n",
       "         ...,\n",
       "         [0.04748887, 0.03099902, 0.04706195, 0.04712604, 0.04740592],\n",
       "         [0.04890174, 0.05082048, 0.04742533, 0.04847824, 0.04779829],\n",
       "         [0.04779987, 0.04635023, 0.04875863, 0.04840135, 0.04808512]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.01824502, 0.01672059, 0.01833855, 0.01818896, 0.01832172],\n",
       "         [0.01805199, 0.0385268 , 0.01815686, 0.01808291, 0.01806194],\n",
       "         [0.01811633, 0.03975366, 0.01799387, 0.01799011, 0.01804841],\n",
       "         ...,\n",
       "         [0.02196886, 0.04699158, 0.02231708, 0.02219519, 0.02197213],\n",
       "         [0.02275706, 0.06136823, 0.02211401, 0.02257964, 0.02224814],\n",
       "         [0.02303052, 0.08227018, 0.02262168, 0.02318415, 0.02290841]],\n",
       " \n",
       "        [[0.8862149 , 0.04284297, 0.8794953 , 0.8874413 , 0.88980585],\n",
       "         [0.8822578 , 0.0224832 , 0.88251734, 0.880378  , 0.88807124],\n",
       "         [0.8827324 , 0.03141889, 0.88898075, 0.89150846, 0.87724453],\n",
       "         ...,\n",
       "         [0.8187353 , 0.01781938, 0.8199137 , 0.81438273, 0.8206483 ],\n",
       "         [0.82913476, 0.02510256, 0.81832385, 0.82666653, 0.82836044],\n",
       "         [0.84707564, 0.02362339, 0.8327203 , 0.83809656, 0.84271586]],\n",
       " \n",
       "        [[0.04736019, 0.04975829, 0.04652222, 0.04692453, 0.04689177],\n",
       "         [0.04701703, 0.0442008 , 0.04785284, 0.04773055, 0.04742486],\n",
       "         [0.04688834, 0.03119836, 0.04704859, 0.04685295, 0.04705413],\n",
       "         ...,\n",
       "         [0.05036286, 0.0385268 , 0.04920484, 0.0498596 , 0.04980615],\n",
       "         [0.05067653, 0.03441864, 0.0501908 , 0.05036336, 0.05061254],\n",
       "         [0.05030388, 0.03277768, 0.05005185, 0.05012209, 0.05058548]]],\n",
       "       dtype=float32),\n",
       " 'X_test': array([[[4.9647376e-01, 2.2349339e-02, 4.9139550e-01, 4.9227020e-01,\n",
       "          4.9485013e-01],\n",
       "         [4.9774724e-01, 1.5415728e-02, 4.9767458e-01, 4.9668208e-01,\n",
       "          5.0161517e-01],\n",
       "         [5.0114667e-01, 5.6241214e-02, 4.9607140e-01, 4.9618360e-01,\n",
       "          5.0042176e-01],\n",
       "         ...,\n",
       "         [5.1077396e-01, 3.0071648e-02, 5.1027280e-01, 5.1035786e-01,\n",
       "          5.1085079e-01],\n",
       "         [5.3517067e-01, 5.0904259e-02, 5.1691258e-01, 5.2949810e-01,\n",
       "          5.2191025e-01],\n",
       "         [5.3892666e-01, 4.4556152e-02, 5.3858471e-01, 5.3936118e-01,\n",
       "          5.4020286e-01]],\n",
       " \n",
       "        [[2.4575429e-04, 2.1031952e-02, 2.5884455e-04, 2.5547057e-04,\n",
       "          2.6778216e-04],\n",
       "         [2.1782759e-04, 2.4510313e-02, 2.4771137e-04, 2.3475674e-04,\n",
       "          2.2550077e-04],\n",
       "         [2.2899832e-04, 7.2802911e-03, 2.1431207e-04, 2.2923312e-04,\n",
       "          2.3677590e-04],\n",
       "         ...,\n",
       "         [6.3114159e-04, 3.3350669e-02, 6.9303543e-04, 6.8217574e-04,\n",
       "          6.5677112e-04],\n",
       "         [6.7163527e-04, 3.1779047e-02, 6.2067033e-04, 6.9322321e-04,\n",
       "          6.3704001e-04],\n",
       "         [6.9816544e-04, 3.1547928e-03, 6.7355239e-04, 6.8769959e-04,\n",
       "          7.0750882e-04]],\n",
       " \n",
       "        [[6.0573947e-03, 1.0785039e-01, 5.8231675e-03, 6.0536349e-03,\n",
       "          5.8957199e-03],\n",
       "         [6.1270995e-03, 9.2485696e-02, 6.0449392e-03, 6.1119646e-03,\n",
       "          6.0905525e-03],\n",
       "         [5.8992179e-03, 5.6996204e-02, 6.0422667e-03, 6.0324240e-03,\n",
       "          5.9714876e-03],\n",
       "         ...,\n",
       "         [5.5667795e-03, 4.5341000e-02, 5.4865028e-03, 5.5657821e-03,\n",
       "          5.5493503e-03],\n",
       "         [5.5372892e-03, 4.1701816e-02, 5.4865028e-03, 5.4862406e-03,\n",
       "          5.4816999e-03],\n",
       "         [5.5694608e-03, 4.6762388e-02, 5.5506295e-03, 5.5816905e-03,\n",
       "          5.6061768e-03]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[8.1547730e-02, 2.3925772e-02, 8.0605529e-02, 8.0803767e-02,\n",
       "          8.0527477e-02],\n",
       "         [8.1183113e-02, 1.9408332e-02, 8.1019685e-02, 8.0570444e-02,\n",
       "          8.1231043e-02],\n",
       "         [8.0319844e-02, 1.6814006e-02, 8.0691032e-02, 8.0117062e-02,\n",
       "          8.0365121e-02],\n",
       "         ...,\n",
       "         [8.0920383e-02, 2.5798811e-02, 8.2855307e-02, 8.2219593e-02,\n",
       "          8.0898203e-02],\n",
       "         [7.9579905e-02, 2.6580768e-02, 8.0696382e-02, 8.0085248e-02,\n",
       "          7.9878040e-02],\n",
       "         [8.1440493e-02, 1.9913908e-02, 8.1019685e-02, 8.0933690e-02,\n",
       "          8.1525996e-02]],\n",
       " \n",
       "        [[5.4456677e-02, 7.2185628e-02, 5.6405734e-02, 5.6063812e-02,\n",
       "          5.4333303e-02],\n",
       "         [5.2478131e-02, 7.6561511e-02, 5.4487281e-02, 5.4059375e-02,\n",
       "          5.2983005e-02],\n",
       "         [5.0362859e-02, 1.0433158e-01, 5.1270258e-02, 5.0883032e-02,\n",
       "          4.9719557e-02],\n",
       "         ...,\n",
       "         [5.2003600e-02, 4.0174495e-02, 5.1216818e-02, 5.1715564e-02,\n",
       "          5.1689532e-02],\n",
       "         [5.1140334e-02, 4.7542419e-02, 5.1374462e-02, 5.1317859e-02,\n",
       "          5.1094212e-02],\n",
       "         [5.1754273e-02, 1.1830473e-01, 5.1459968e-02, 5.1484894e-02,\n",
       "          5.0977848e-02]],\n",
       " \n",
       "        [[2.8485148e-03, 3.0000001e-01, 3.2313820e-03, 3.2617399e-03,\n",
       "          2.8807733e-03],\n",
       "         [3.0132819e-03, 3.4852371e-01, 2.7888413e-03, 2.9855552e-03,\n",
       "          2.7116477e-03],\n",
       "         [3.2618288e-03, 3.4505114e-01, 2.9530544e-03, 3.2562162e-03,\n",
       "          2.9033236e-03],\n",
       "         ...,\n",
       "         [5.5071283e-03, 1.3351245e-01, 5.7446789e-03, 5.6921644e-03,\n",
       "          5.5416836e-03],\n",
       "         [5.3116418e-03, 1.5315190e-01, 5.4023364e-03, 5.3717899e-03,\n",
       "          5.3641018e-03],\n",
       "         [4.9430104e-03, 1.4965042e-01, 5.1629748e-03, 5.1397947e-03,\n",
       "          5.0117560e-03]]], dtype=float32),\n",
       " 'y_train': array([0.00547563, 0.00899572, 0.05102773, ..., 0.02441389, 0.89530066,\n",
       "        0.04494733]),\n",
       " 'y_test': array([0.63573865, 0.00098581, 0.00542201, ..., 0.09722059, 0.04803847,\n",
       "        0.00318643]),\n",
       " 'test_df':                    open         high          low        close     adjclose  \\\n",
       " 2020-04-07  2017.109985  2035.719971  1997.619995  2011.599976  2011.599976   \n",
       " 1997-10-13     3.927083     4.041667     3.927083     4.000000     4.000000   \n",
       " 2003-02-05    22.180000    22.500000    22.030001    22.170000    22.170000   \n",
       " 2022-02-10  3167.000000  3214.330078  3155.000000  3180.070068  3180.070068   \n",
       " 2021-10-06  3213.530029  3264.340088  3198.620117  3262.010010  3262.010010   \n",
       " ...                 ...          ...          ...          ...          ...   \n",
       " 1998-08-21    21.208332    21.713543    20.541668    21.614582    21.614582   \n",
       " 2017-02-13   831.619995   843.000000   828.549988   836.530029   836.530029   \n",
       " 2013-10-10   304.630005   306.700012   302.589996   305.170013   305.170013   \n",
       " 2012-01-31   194.000000   195.630005   189.699997   194.440002   194.440002   \n",
       " 1998-08-27    20.729168    20.833332    19.833332    19.833332    19.833332   \n",
       " \n",
       "               volume ticker  \n",
       " 2020-04-07   5114000   AMZN  \n",
       " 1997-10-13    814800   AMZN  \n",
       " 2003-02-05   5343100   AMZN  \n",
       " 2022-02-10   3413400   AMZN  \n",
       " 2021-10-06   2533000   AMZN  \n",
       " ...              ...    ...  \n",
       " 1998-08-21  15136200   AMZN  \n",
       " 2017-02-13   4172600   AMZN  \n",
       " 2013-10-10   2555100   AMZN  \n",
       " 2012-01-31  12772200   AMZN  \n",
       " 1998-08-27  16027200   AMZN  \n",
       " \n",
       " [1238 rows x 7 columns]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 12:38:54.936873: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3004.3745"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3004.37"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(future_price, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
